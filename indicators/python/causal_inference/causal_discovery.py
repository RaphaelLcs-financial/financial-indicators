"""
å› æœå‘ç°å’Œæ¨æ–­æŒ‡æ ‡
Causal Discovery and Inference Indicator

åŸºäºå› æœæ¨æ–­çš„å¸‚åœºé©±åŠ¨å› ç´ åˆ†æå’Œå› æœæ•ˆåº”è¯„ä¼°
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

try:
    from causalnex.structure import DAGRegressor
    from causalnex.structure.notears import from_pandas
    from causalnex.plots import plot_structure, NODE_STYLE, EDGE_STYLE
    from pgmpy.models import BayesianNetwork
    from pgmpy.estimators import BicScore, K2Score
    import networkx as nx
    CAUSAL_LIBRARIES_AVAILABLE = True
    print("ğŸ”— å› æœæ¨æ–­åº“å·²å¯ç”¨")
except ImportError:
    CAUSAL_LIBRARIES_AVAILABLE = False
    print("âš ï¸ å› æœæ¨æ–­åº“ä¸å¯ç”¨")

class CausalDiscoveryIndicator:
    """
    å› æœå‘ç°äº¤æ˜“æŒ‡æ ‡

    åŸºäºå› æœæ¨æ–­ç†è®ºè¯†åˆ«å¸‚åœºé©±åŠ¨å› ç´ 
    è¯„ä¼°å˜é‡é—´çš„å› æœå…³ç³»å’Œå› æœæ•ˆåº”
    """

    def __init__(self, method: str = 'notears', significance_level: float = 0.05,
                 max_lag: int = 5, bootstrap_samples: int = 1000):
        """
        åˆå§‹åŒ–å› æœå‘ç°æŒ‡æ ‡

        Args:
            method: å› æœå‘ç°æ–¹æ³• ('notears', 'pc', 'ges', 'lingam')
            significance_level: æ˜¾è‘—æ€§æ°´å¹³
            max_lag: æœ€å¤§æ»åé˜¶æ•°
            bootstrap_samples: è‡ªåŠ©æ³•æ ·æœ¬æ•°
        """
        self.method = method
        self.significance_level = significance_level
        self.max_lag = max_lag
        self.bootstrap_samples = bootstrap_samples

        # å› æœå›¾
        self.causal_graph = nx.DiGraph()
        self.causal_strengths = {}
        self.causal_directions = {}

        # åˆ†æç»“æœ
        self.causal_relationships = {}
        self.causal_effects = {}
        self.confounding_factors = {}

        # ç¨³å¥æ€§æ£€éªŒ
        self.robustness_results = {}

    def preprocess_time_series(self, data: pd.DataFrame) -> pd.DataFrame:
        """é¢„å¤„ç†æ—¶é—´åºåˆ—æ•°æ®"""
        print("ğŸ“Š é¢„å¤„ç†æ—¶é—´åºåˆ—æ•°æ®...")

        processed_data = data.copy()

        # è®¡ç®—æ”¶ç›Šç‡
        for col in processed_data.columns:
            if processed_data[col].dtype in ['float64', 'int64']:
                processed_data[f'{col}_returns'] = processed_data[col].pct_change().fillna(0)

        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        for col in processed_data.columns:
            if processed_data[col].dtype in ['float64', 'int64'] and not col.endswith('_returns'):
                # ç§»åŠ¨å¹³å‡
                processed_data[f'{col}_sma_5'] = processed_data[col].rolling(5).mean().fillna(0)
                processed_data[f'{col}_sma_20'] = processed_data[col].rolling(20).mean().fillna(0)

                # æ³¢åŠ¨ç‡
                returns = processed_data[f'{col}_returns'] if f'{col}_returns' in processed_data.columns else processed_data[col].pct_change().fillna(0)
                processed_data[f'{col}_volatility'] = returns.rolling(10).std().fillna(0)

        return processed_data.fillna(0)

    def discover_causal_structure(self, data: pd.DataFrame) -> nx.DiGraph:
        """å‘ç°å› æœç»“æ„"""
        print(f"ğŸ” ä½¿ç”¨ {self.method} æ–¹æ³•å‘ç°å› æœç»“æ„...")

        if self.method == 'notears' and CAUSAL_LIBRARIES_AVAILABLE:
            return self._discover_notears(data)
        else:
            return self._discover_granger_causality(data)

    def _discover_notears(self, data: pd.DataFrame) -> nx.DiGraph:
        """ä½¿ç”¨NOTEARSæ–¹æ³•å‘ç°å› æœç»“æ„"""
        try:
            # NOTEARSéœ€è¦è¿ç»­æ•°æ®
            continuous_data = data.select_dtypes(include=[np.number])

            # ç»“æ„å­¦ä¹ 
            structural_model = from_pandas(continuous_data, tabu_edges=[], tabu_parent_nodes=[])

            # åˆ›å»ºæœ‰å‘å›¾
            graph = nx.DiGraph()
            for i, col1 in enumerate(continuous_data.columns):
                for j, col2 in enumerate(continuous_data.columns):
                    if i != j and structural_model[i, j] != 0:
                        weight = abs(structural_model[i, j])
                        graph.add_edge(col1, col2, weight=weight)

            return graph
        except Exception as e:
            print(f"NOTEARSæ–¹æ³•å¤±è´¥: {e}")
            return self._discover_granger_causality(data)

    def _discover_granger_causality(self, data: pd.DataFrame) -> nx.DiGraph:
        """ä½¿ç”¨Grangerå› æœå‘ç°"""
        from statsmodels.tsa.stattools import grangercausalitytests

        graph = nx.DiGraph()
        variables = data.select_dtypes(include=[np.number]).columns

        for i, var1 in enumerate(variables):
            for j, var2 in enumerate(variables):
                if i != j:
                    try:
                        # Grangerå› æœæ£€éªŒ
                        test_result = grangercausalitytests(
                            data[[var1, var2]].dropna(),
                            maxlag=min(self.max_lag, len(data) // 10)
                        )

                        # è·å–æœ€å°på€¼
                        min_p_value = min([result[0]['ssr_ftest'][1] for result in test_result.values()])

                        # å¦‚æœæ˜¾è‘—ï¼Œæ·»åŠ è¾¹
                        if min_p_value < self.significance_level:
                            strength = -np.log(min_p_value)  # è´Ÿå¯¹æ•°å¼ºåº¦
                            graph.add_edge(var2, var1, weight=strength, p_value=min_p_value)

                    except Exception as e:
                        print(f"Grangerå› æœæ£€éªŒå¤±è´¥ {var2} -> {var1}: {e}")

        return graph

    def estimate_causal_effects(self, data: pd.DataFrame, treatment: str, outcome: str) -> Dict[str, float]:
        """ä¼°è®¡å› æœæ•ˆåº”"""
        print(f"ğŸ“ˆ ä¼°è®¡å› æœæ•ˆåº”: {treatment} -> {outcome}")

        # æ–¹æ³•1: å›å½’è°ƒæ•´
        regression_effect = self._regression_adjustment(data, treatment, outcome)

        # æ–¹æ³•2: å€¾å‘å¾—åˆ†åŒ¹é…
        propensity_effect = self._propensity_score_matching(data, treatment, outcome)

        # æ–¹æ³•3: åŒé‡å·®åˆ†
        diff_effect = self._difference_in_differences(data, treatment, outcome)

        # ç»¼åˆå› æœæ•ˆåº”
        causal_effects = {
            'regression_adjustment': regression_effect,
            'propensity_score_matching': propensity_effect,
            'difference_in_differences': diff_effect,
            'average_effect': np.mean([regression_effect, propensity_effect, diff_effect])
        }

        self.causal_effects[(treatment, outcome)] = causal_effects

        return causal_effects

    def _regression_adjustment(self, data: pd.DataFrame, treatment: str, outcome: str) -> float:
        """å›å½’è°ƒæ•´ä¼°è®¡å› æœæ•ˆåº”"""
        from sklearn.linear_model import LinearRegression
        from sklearn.preprocessing import StandardScaler

        # é€‰æ‹©åå˜é‡
        covariates = [col for col in data.columns if col not in [treatment, outcome]]
        covariates = covariates[:10]  # é™åˆ¶åå˜é‡æ•°é‡

        # å‡†å¤‡æ•°æ®
        X = data[[treatment] + covariates].fillna(0)
        y = data[outcome].fillna(0)

        # æ ‡å‡†åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # çº¿æ€§å›å½’
        model = LinearRegression()
        model.fit(X_scaled, y)

        # æ²»ç†å˜é‡ç³»æ•°ä¸ºå› æœæ•ˆåº”
        treatment_idx = 0  # æ²»ç†å˜é‡æ˜¯ç¬¬ä¸€ä¸ªç‰¹å¾
        causal_effect = model.coef_[treatment_idx]

        return causal_effect

    def _propensity_score_matching(self, data: pd.DataFrame, treatment: str, outcome: str) -> float:
        """å€¾å‘å¾—åˆ†åŒ¹é…"""
        from sklearn.linear_model import LogisticRegression
        from sklearn.neighbors import NearestNeighbors

        # äºŒå€¼åŒ–å¤„ç†å˜é‡
        treatment_median = data[treatment].median()
        treatment_binary = (data[treatment] > treatment_median).astype(int)

        # é€‰æ‹©åå˜é‡
        covariates = [col for col in data.columns if col not in [treatment, outcome]]
        covariates = covariates[:5]  # é™åˆ¶æ•°é‡

        # è®¡ç®—å€¾å‘å¾—åˆ†
        X = data[covariates].fillna(0)
        propensity_model = LogisticRegression()
        propensity_model.fit(X, treatment_binary)
        propensity_scores = propensity_model.predict_proba(X)[:, 1]

        # åŒ¹é…
        treated_mask = treatment_binary == 1
        control_mask = treatment_binary == 0

        if treated_mask.sum() > 0 and control_mask.sum() > 0:
            # æ‰¾åˆ°æœ€è¿‘é‚»åŒ¹é…
            treated_scores = propensity_scores[treated_mask]
            control_scores = propensity_scores[control_mask]

            treated_outcomes = data[outcome][treated_mask]
            control_outcomes = data[outcome][control_mask]

            # ç®€å•åŒ¹é…ï¼šæ¯”è¾ƒå¹³å‡å€¼
            ate = treated_outcomes.mean() - control_outcomes.mean()
        else:
            ate = 0

        return ate

    def _difference_in_differences(self, data: pd.DataFrame, treatment: str, outcome: str) -> float:
        """åŒé‡å·®åˆ†æ³•"""
        # ç®€åŒ–çš„DIDå®ç°
        mid_point = len(data) // 2

        # å‰ã€åæœŸçš„å¤„ç†ç»„å’Œå¯¹ç…§ç»„
        treatment_binary = (data[treatment] > data[treatment].median()).astype(int)

        # å‰ã€åæœŸç»“æœ
        pre_treatment = data[outcome][:mid_point]
        post_treatment = data[outcome][mid_point:]

        pre_treatment_binary = treatment_binary[:mid_point]
        post_treatment_binary = treatment_binary[mid_point:]

        # è®¡ç®—DIDä¼°è®¡é‡
        pre_diff = pre_treatment[pre_treatment_binary == 1].mean() - pre_treatment[pre_treatment_binary == 0].mean()
        post_diff = post_treatment[post_treatment_binary == 1].mean() - post_treatment[post_treatment_binary == 0].mean()

        did_estimate = post_diff - pre_diff

        return did_estimate

    def identify_confounding_factors(self, causal_graph: nx.DiGraph, data: pd.DataFrame) -> Dict[str, List[str]]:
        """è¯†åˆ«æ··æ‚å› ç´ """
        print("ğŸ” è¯†åˆ«æ··æ‚å› ç´ ...")

        confounding_factors = {}

        for edge in causal_graph.edges():
            cause, effect = edge

            # æŸ¥æ‰¾å…±åŒåŸå› ï¼ˆæ··æ‚å› ç´ ï¼‰
            common_causes = set()
            for node in causal_graph.nodes():
                if node != cause and node != effect:
                    # æ£€æŸ¥æ˜¯å¦åŒæ—¶æŒ‡å‘causeå’Œeffect
                    has_path_to_cause = nx.has_path(causal_graph, node, cause) if node in causal_graph and cause in causal_graph else False
                    has_path_to_effect = nx.has_path(causal_graph, node, effect) if node in causal_graph and effect in causal_graph else False

                    if has_path_to_cause and has_path_to_effect:
                        common_causes.add(node)

            confounding_factors[(cause, effect)] = list(common_causes)

        self.confounding_factors = confounding_factors
        return confounding_factors

    def perform_counterfactual_analysis(self, data: pd.DataFrame, intervention: Dict[str, float]) -> Dict[str, Any]:
        """æ‰§è¡Œåäº‹å®åˆ†æ"""
        print("ğŸ”® æ‰§è¡Œåäº‹å®åˆ†æ...")

        results = {}

        for variable, intervention_value in intervention.items():
            print(f"åˆ†æå¹²é¢„: {variable} = {intervention_value}")

            # åˆ›å»ºåäº‹å®æ•°æ®
            counterfactual_data = data.copy()
            counterfactual_data[variable] = intervention_value

            # é¢„æµ‹åäº‹å®ç»“æœ
            counterfactual_predictions = self._predict_counterfactual_outcomes(counterfactual_data, variable)

            # è®¡ç®—å› æœæ•ˆåº”
            baseline_predictions = self._predict_counterfactual_outcomes(data, variable)
            causal_effects = {outcome: counterfactual_predictions[outcome] - baseline_predictions[outcome]
                              for outcome in counterfactual_predictions}

            results[variable] = {
                'intervention_value': intervention_value,
                'counterfactual_predictions': counterfactual_predictions,
                'causal_effects': causal_effects,
                'effect_magnitude': np.mean(list(causal_effects.values()))
            }

        return results

    def _predict_counterfactual_outcomes(self, data: pd.DataFrame, intervention_variable: str) -> Dict[str, float]:
        """é¢„æµ‹åäº‹å®ç»“æœ"""
        # ç®€åŒ–çš„é¢„æµ‹æ–¹æ³•
        outcomes = {}

        # é€‰æ‹©å—å½±å“çš„å˜é‡
        affected_variables = [col for col in data.columns if col != intervention_variable]

        for outcome in affected_variables[:5]:  # é™åˆ¶æ•°é‡
            # ç®€å•çº¿æ€§å…³ç³»
            correlation = data[[intervention_variable, outcome]].corr().iloc[0, 1]
            if not np.isnan(correlation):
                # åŸºäºç›¸å…³æ€§é¢„æµ‹
                intervention_value = data[intervention_variable].iloc[-1]
                baseline_value = data[outcome].iloc[-1]
                predicted_change = correlation * (intervention_value - data[intervention_variable].mean())
                outcomes[outcome] = baseline_value + predicted_change
            else:
                outcomes[outcome] = data[outcome].iloc[-1]

        return outcomes

    def assess_causal_robustness(self, data: pd.DataFrame) -> Dict[str, Any]:
        """è¯„ä¼°å› æœå…³ç³»çš„ç¨³å¥æ€§"""
        print("ğŸ” è¯„ä¼°å› æœå…³ç³»çš„ç¨³å¥æ€§...")

        robustness_results = {}

        # è‡ªåŠ©æ³•æ£€éªŒ
        bootstrap_results = self._bootstrap_causal_discovery(data)

        # æ•æ„Ÿæ€§åˆ†æ
        sensitivity_results = self._sensitivity_analysis(data)

        # ç¨³å¥æ€§è¯„åˆ†
        robustness_scores = self._calculate_robustness_scores(bootstrap_results, sensitivity_results)

        self.robustness_results = {
            'bootstrap_results': bootstrap_results,
            'sensitivity_results': sensitivity_results,
            'robustness_scores': robustness_scores
        }

        return self.robustness_results

    def _bootstrap_causal_discovery(self, data: pd.DataFrame) -> Dict[str, float]:
        """è‡ªåŠ©æ³•å› æœå‘ç°"""
        edge_frequencies = {}

        for _ in range(self.bootstrap_samples):
            # é‡é‡‡æ ·
            sample_data = data.sample(n=len(data), replace=True)

            # å› æœå‘ç°
            bootstrap_graph = self.discover_causal_structure(sample_data)

            # è®°å½•è¾¹é¢‘ç‡
            for edge in bootstrap_graph.edges():
                edge_key = (edge[0], edge[1])
                edge_frequencies[edge_key] = edge_frequencies.get(edge_key, 0) + 1

        # è®¡ç®—é¢‘ç‡
        for edge_key in edge_frequencies:
            edge_frequencies[edge_key] /= self.bootstrap_samples

        return edge_frequencies

    def _sensitivity_analysis(self, data: pd.DataFrame) -> Dict[str, float]:
        """æ•æ„Ÿæ€§åˆ†æ"""
        sensitivity_results = {}

        # æ·»åŠ å™ªå£°
        noise_levels = [0.01, 0.05, 0.1]

        for noise_level in noise_levels:
            noisy_data = data.copy()
            for col in noisy_data.select_dtypes(include=[np.number]).columns:
                noise = np.random.normal(0, noise_level * noisy_data[col].std(), len(noisy_data))
                noisy_data[col] += noise

            # å› æœå‘ç°
            noisy_graph = self.discover_causal_structure(noisy_data)

            # æ¯”è¾ƒä¸åŸå›¾çš„ç›¸ä¼¼æ€§
            original_graph = self.discover_causal_structure(data)
            similarity = self._calculate_graph_similarity(original_graph, noisy_graph)

            sensitivity_results[noise_level] = similarity

        return sensitivity_results

    def _calculate_graph_similarity(self, graph1: nx.DiGraph, graph2: nx.DiGraph) -> float:
        """è®¡ç®—å›¾ç›¸ä¼¼åº¦"""
        edges1 = set(graph1.edges())
        edges2 = set(graph2.edges())

        if len(edges1) == 0 and len(edges2) == 0:
            return 1.0

        intersection = edges1.intersection(edges2)
        union = edges1.union(edges2)

        if len(union) == 0:
            return 0.0

        jaccard_similarity = len(intersection) / len(union)
        return jaccard_similarity

    def _calculate_robustness_scores(self, bootstrap_results: Dict, sensitivity_results: Dict) -> Dict[str, float]:
        """è®¡ç®—ç¨³å¥æ€§è¯„åˆ†"""
        robustness_scores = {}

        # è¾¹é¢‘ç‡è¯„åˆ†
        if bootstrap_results:
            avg_edge_frequency = np.mean(list(bootstrap_results.values()))
            robustness_scores['edge_frequency_score'] = avg_edge_frequency

        # æ•æ„Ÿæ€§è¯„åˆ†
        if sensitivity_results:
            avg_sensitivity = np.mean(list(sensitivity_results.values()))
            robustness_scores['sensitivity_score'] = avg_sensitivity

        # ç»¼åˆç¨³å¥æ€§è¯„åˆ†
        if robustness_scores:
            robustness_scores['overall_robustness'] = np.mean(list(robustness_scores.values()))
        else:
            robustness_scores['overall_robustness'] = 0.5

        return robustness_scores

    def generate_causal_trading_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆå› æœäº¤æ˜“ä¿¡å·"""
        print("ğŸ“Š ç”Ÿæˆå› æœäº¤æ˜“ä¿¡å·...")

        # å› æœå‘ç°
        causal_graph = self.discover_causal_structure(data)

        # è¯†åˆ«å…³é”®é©±åŠ¨å› ç´ 
        key_drivers = self._identify_key_drivers(causal_graph)

        # ä¼°è®¡å› æœæ•ˆåº”
        causal_effects = {}
        for driver in key_drivers[:3]:  # åˆ†æå‰3ä¸ªé©±åŠ¨å› ç´ 
            for outcome in data.select_dtypes(include=[np.number]).columns[:3]:
                if driver != outcome:
                    effects = self.estimate_causal_effects(data, driver, outcome)
                    causal_effects[(driver, outcome)] = effects['average_effect']

        # ç”Ÿæˆä¿¡å·
        signals = []

        for i in range(len(data)):
            window_data = data.iloc[max(0, i-20):i+1]

            # åŸºäºå› æœå…³ç³»çš„ä¿¡å·
            causal_signal = self._calculate_causal_signal(window_data, causal_effects)

            # åŸºäºç¨³å¥æ€§çš„ä¿¡å·
            robustness_signal = self._calculate_robustness_signal(causal_effects)

            # ç»¼åˆä¿¡å·
            combined_signal = 0.6 * causal_signal + 0.4 * robustness_signal

            signals.append(np.clip(combined_signal, -1, 1))

        signals_df = pd.DataFrame({
            'signal': signals,
            'causal_confidence': self._calculate_causal_confidence(causal_effects),
            'robustness_score': self.robustness_results.get('robustness_scores', {}).get('overall_robustness', 0.5)
        }, index=data.index)

        return signals_df

    def _identify_key_drivers(self, causal_graph: nx.DiGraph) -> List[str]:
        """è¯†åˆ«å…³é”®é©±åŠ¨å› ç´ """
        # åŸºäºå‡ºåº¦è¯†åˆ«é©±åŠ¨å› ç´ 
        out_degrees = dict(causal_graph.out_degree())
        key_drivers = sorted(out_degrees.items(), key=lambda x: x[1], reverse=True)

        return [driver[0] for driver in key_drivers[:5]]

    def _calculate_causal_signal(self, data: pd.DataFrame, causal_effects: Dict) -> float:
        """è®¡ç®—å› æœä¿¡å·"""
        signal = 0

        for (driver, outcome), effect in causal_effects.items():
            if driver in data.columns and outcome in data.columns:
                # è·å–æœ€æ–°æ•°æ®
                driver_value = data[driver].iloc[-1]
                outcome_value = data[outcome].iloc[-1]

                # åŸºäºå› æœæ•ˆåº”å’Œå½“å‰å€¼ç”Ÿæˆä¿¡å·
                if effect > 0:  # æ­£å‘å› æœæ•ˆåº”
                    if driver_value > data[driver].median():
                        signal += 0.5
                    else:
                        signal -= 0.3
                else:  # è´Ÿå‘å› æœæ•ˆåº”
                    if driver_value > data[driver].median():
                        signal -= 0.5
                    else:
                        signal += 0.3

        return signal / max(len(causal_effects), 1)

    def _calculate_robustness_signal(self, causal_effects: Dict) -> float:
        """è®¡ç®—ç¨³å¥æ€§ä¿¡å·"""
        # åŸºäºå› æœæ•ˆåº”çš„ç¨³å¥æ€§ç”Ÿæˆä¿¡å·
        if not causal_effects:
            return 0

        effect_magnitudes = [abs(effect) for effect in causal_effects.values()]
        avg_magnitude = np.mean(effect_magnitudes)

        # æ•ˆåº”è¶Šå¼ºï¼Œä¿¡å·è¶Šå¼º
        robustness_signal = min(avg_magnitude / 0.1, 1.0)  # æ ‡å‡†åŒ–

        return robustness_signal

    def _calculate_causal_confidence(self, causal_effects: Dict) -> float:
        """è®¡ç®—å› æœç½®ä¿¡åº¦"""
        if not causal_effects:
            return 0.5

        # åŸºäºæ•ˆåº”å¤§å°å’Œä¸€è‡´æ€§è®¡ç®—ç½®ä¿¡åº¦
        effect_magnitudes = [abs(effect) for effect in causal_effects.values()]
        effect_consistency = 1 - (np.std(effect_magnitudes) / (np.mean(effect_magnitudes) + 1e-6))

        return effect_consistency

    def get_causal_insights(self) -> Dict[str, Any]:
        """è·å–å› æœæ´å¯Ÿ"""
        return {
            'causal_relationships': self.causal_relationships,
            'causal_effects': self.causal_effects,
            'confounding_factors': self.confounding_factors,
            'robustness_results': self.robustness_results,
            'method': self.method,
            'significance_level': self.significance_level
        }

    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'method': self.method,
            'significance_level': self.significance_level,
            'max_lag': self.max_lag,
            'bootstrap_samples': self.bootstrap_samples,
            'causal_libraries_available': CAUSAL_LIBRARIES_AVAILABLE,
            'graph_stats': {
                'num_nodes': self.causal_graph.number_of_nodes(),
                'num_edges': self.causal_graph.number_of_edges(),
                'density': nx.density(self.causal_graph) if len(self.causal_graph.nodes()) > 0 else 0
            },
            'model_type': 'Causal Discovery and Inference Indicator'
        }

# ä¾¿æ·å‡½æ•°
def create_causal_discovery_indicator(method: str = 'notears') -> CausalDiscoveryIndicator:
    """åˆ›å»ºå› æœå‘ç°æŒ‡æ ‡å®ä¾‹"""
    return CausalDiscoveryIndicator(method)

def quick_causal_analysis(data: pd.DataFrame) -> Dict[str, Any]:
    """å¿«é€Ÿå› æœåˆ†æ"""
    causal_analyzer = CausalDiscoveryIndicator()

    # å› æœå‘ç°
    causal_graph = causal_analyzer.discover_causal_structure(data)

    # ç¨³å¥æ€§è¯„ä¼°
    robustness_results = causal_analyzer.assess_causal_robustness(data)

    # ç”Ÿæˆäº¤æ˜“ä¿¡å·
    signals = causal_analyzer.generate_causal_trading_signals(data)

    return {
        'causal_graph_stats': {
            'num_nodes': causal_graph.number_of_nodes(),
            'num_edges': causal_graph.number_of_edges()
        },
        'robustness_results': robustness_results,
        'latest_signal': signals['signal'].iloc[-1] if len(signals) > 0 else 0,
        'causal_confidence': signals['causal_confidence'].iloc[-1] if len(signals) > 0 else 0,
        'model_info': causal_analyzer.get_model_info()
    }