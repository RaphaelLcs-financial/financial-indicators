"""
å¤šæ¨¡æ€å¸‚åœºåˆ†æå™¨
Multimodal Market Analyzer

èåˆæ–‡æœ¬ã€å›¾åƒã€æ—¶åºæ•°æ®çš„è·¨æ¨¡æ€å¸‚åœºåˆ†ææ¡†æ¶
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from transformers import AutoTokenizer, AutoModel
    TORCH_AVAILABLE = True
    print("ğŸ§  PyTorch å·²å¯ç”¨")
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorch ä¸å¯ç”¨")

class MultimodalMarketAnalyzer:
    """
    å¤šæ¨¡æ€å¸‚åœºåˆ†æå™¨

    æ•´åˆå¤šç§æ•°æ®æ¨¡æ€è¿›è¡Œç»¼åˆå¸‚åœºåˆ†æï¼š
    - æ—¶åºæ•°æ®ï¼šä»·æ ¼ã€æˆäº¤é‡ç­‰ä¼ ç»Ÿé‡‘èæ•°æ®
    - æ–‡æœ¬æ•°æ®ï¼šæ–°é—»ã€æŠ¥å‘Šã€ç¤¾äº¤åª’ä½“æƒ…ç»ª
    - å›¾åƒæ•°æ®ï¼šå›¾è¡¨æ¨¡å¼ã€æŠ€æœ¯å½¢æ€è¯†åˆ«
    """

    def __init__(self, modalities: List[str] = None, fusion_method: str = 'attention'):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€åˆ†æå™¨

        Args:
            modalities: ä½¿ç”¨çš„æ¨¡æ€åˆ—è¡¨ ['time_series', 'text', 'image']
            fusion_method: èåˆæ–¹æ³• ['attention', 'concat', 'transformer']
        """
        self.modalities = modalities or ['time_series', 'text', 'image']
        self.fusion_method = fusion_method

        # æ¨¡æ€å¤„ç†å™¨
        self.time_series_processor = TimeSeriesProcessor()
        self.text_processor = TextProcessor()
        self.image_processor = ImageProcessor()

        # èåˆæ¨¡å‹
        self.fusion_model = None
        self.is_trained = False

        # åˆ†æç»“æœ
        self.multimodal_features = {}
        self.cross_modal_correlations = {}
        self.fusion_weights = {}

    def process_time_series_data(self, data: pd.DataFrame) -> Dict[str, np.ndarray]:
        """å¤„ç†æ—¶åºæ•°æ®"""
        print("ğŸ“ˆ å¤„ç†æ—¶åºæ•°æ®...")

        features = {}

        # åŸºç¡€ç»Ÿè®¡ç‰¹å¾
        for col in data.select_dtypes(include=[np.number]).columns:
            col_data = data[col].dropna()
            if len(col_data) > 0:
                features[f'{col}_mean'] = [np.mean(col_data)]
                features[f'{col}_std'] = [np.std(col_data)]
                features[f'{col}_trend'] = [np.polyfit(range(len(col_data)), col_data.values, 1)[0]]
                features[f'{col}_volatility'] = [np.std(np.diff(col_data.values))]

        # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        if 'close' in data.columns:
            close_prices = data['close'].dropna()
            if len(close_prices) > 20:
                # ç§»åŠ¨å¹³å‡
                features['sma_20'] = [close_prices.rolling(20).mean().iloc[-1]]
                features['ema_12'] = [close_prices.ewm(span=12).mean().iloc[-1]]

                # RSI
                returns = close_prices.pct_change().dropna()
                if len(returns) > 14:
                    gains = returns[returns > 0]
                    losses = -returns[returns < 0]
                    avg_gain = np.mean(gains[-14:]) if len(gains) > 0 else 0
                    avg_loss = np.mean(losses[-14:]) if len(losses) > 0 else 0
                    if avg_loss > 0:
                        rsi = 100 - (100 / (1 + avg_gain / avg_loss))
                        features['rsi'] = [rsi]

        return features

    def process_text_data(self, text_data: List[str]) -> Dict[str, np.ndarray]:
        """å¤„ç†æ–‡æœ¬æ•°æ®"""
        print("ğŸ“ å¤„ç†æ–‡æœ¬æ•°æ®...")

        features = {}

        # ç®€å•çš„æ–‡æœ¬ç‰¹å¾
        all_text = ' '.join(text_data)

        # åŸºç¡€ç»Ÿè®¡
        features['text_length'] = [len(all_text)]
        features['num_articles'] = [len(text_data)]

        # æƒ…ç»ªåˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
        positive_words = ['bull', 'growth', 'increase', 'rise', 'positive', 'up', 'gain', 'profit']
        negative_words = ['bear', 'decline', 'decrease', 'fall', 'negative', 'down', 'loss', 'risk']

        positive_count = sum(1 for word in positive_words if word in all_text.lower())
        negative_count = sum(1 for word in negative_words if word in all_text.lower())

        total_sentiment_words = positive_count + negative_count
        if total_sentiment_words > 0:
            sentiment_score = (positive_count - negative_count) / total_sentiment_words
        else:
            sentiment_score = 0

        features['sentiment_score'] = [sentiment_score]
        features['positive_word_count'] = [positive_count]
        features['negative_word_count'] = [negative_count]

        return features

    def process_image_data(self, image_data: List[np.ndarray]) -> Dict[str, np.ndarray]:
        """å¤„ç†å›¾åƒæ•°æ®"""
        print("ğŸ–¼ï¸ å¤„ç†å›¾åƒæ•°æ®...")

        features = {}

        for i, image in enumerate(image_data):
            # ç®€å•çš„å›¾åƒç‰¹å¾
            if len(image.shape) == 3:
                # é¢œè‰²ç‰¹å¾
                mean_colors = np.mean(image, axis=(0, 1))
                features[f'image_{i}_mean_r'] = [mean_colors[0]]
                features[f'image_{i}_mean_g'] = [mean_colors[1]]
                features[f'image_{i}_mean_b'] = [mean_colors[2]]

                # çº¹ç†ç‰¹å¾ï¼ˆæ ‡å‡†å·®ï¼‰
                std_colors = np.std(image, axis=(0, 1))
                features[f'image_{i}_std_r'] = [std_colors[0]]
                features[f'image_{i}_std_g'] = [std_colors[1]]
                features[f'image_{i}_std_b'] = [std_colors[2]]

        return features

    def fuse_modalities(self, modality_features: Dict[str, Dict[str, np.ndarray]]) -> np.ndarray:
        """èåˆå¤šæ¨¡æ€ç‰¹å¾"""
        print("ğŸ”— èåˆå¤šæ¨¡æ€ç‰¹å¾...")

        # æ”¶é›†æ‰€æœ‰ç‰¹å¾
        all_features = []
        feature_names = []

        for modality, features in modality_features.items():
            for feature_name, feature_value in features.items():
                all_features.append(feature_value)
                feature_names.append(f"{modality}_{feature_name}")

        if not all_features:
            return np.array([])

        # ç‰¹å¾å¯¹é½
        max_length = max(len(feat) for feat in all_features)
        aligned_features = []

        for feature in all_features:
            if len(feature) < max_length:
                # å¡«å……åˆ°ç›¸åŒé•¿åº¦
                padded_feature = np.pad(feature, (0, max_length - len(feature)), 'constant')
            else:
                padded_feature = feature[:max_length]
            aligned_features.append(padded_feature)

        # èåˆæ–¹æ³•
        if self.fusion_method == 'concat':
            fused_features = np.concatenate(aligned_features, axis=0)
        elif self.fusion_method == 'attention':
            fused_features = self._attention_fusion(aligned_features)
        else:
            # é»˜è®¤ç®€å•å¹³å‡
            fused_features = np.mean(aligned_features, axis=0)

        return fused_features

    def _attention_fusion(self, features: List[np.ndarray]) -> np.ndarray:
        """æ³¨æ„åŠ›æœºåˆ¶èåˆ"""
        if not features:
            return np.array([])

        # ç®€åŒ–çš„æ³¨æ„åŠ›æœºåˆ¶
        feature_matrix = np.array(features)

        # è®¡ç®—æ³¨æ„åŠ›æƒé‡
        attention_weights = np.exp(feature_matrix.sum(axis=1))
        attention_weights = attention_weights / attention_weights.sum()

        # åŠ æƒèåˆ
        fused_features = np.average(feature_matrix, axis=0, weights=attention_weights)

        return fused_features

    def analyze_cross_modal_correlations(self, modality_features: Dict[str, Dict[str, np.ndarray]]) -> Dict[str, float]:
        """åˆ†æè·¨æ¨¡æ€ç›¸å…³æ€§"""
        print("ğŸ”— åˆ†æè·¨æ¨¡æ€ç›¸å…³æ€§...")

        correlations = {}

        # æå–å„æ¨¡æ€çš„ä»£è¡¨ç‰¹å¾
        modality_representations = {}
        for modality, features in modality_features.items():
            if features:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾ä½œä¸ºä»£è¡¨
                first_feature = list(features.values())[0]
                if len(first_feature) > 0:
                    modality_representations[modality] = first_feature[0]

        # è®¡ç®—æ¨¡æ€é—´ç›¸å…³æ€§
        modalities = list(modality_representations.keys())
        for i, mod1 in enumerate(modalities):
            for j, mod2 in enumerate(modalities[i+1:], i+1):
                if mod1 in modality_representations and mod2 in modality_representations:
                    # ç®€åŒ–çš„ç›¸å…³æ€§è®¡ç®—
                    corr = np.corrcoef(
                        [modality_representations[mod1]],
                        [modality_representations[mod2]]
                    )[0, 1]
                    correlations[f"{mod1}_{mod2}"] = corr

        self.cross_modal_correlations = correlations
        return correlations

    def generate_multimodal_signals(self, time_series_data: pd.DataFrame,
                                   text_data: List[str] = None,
                                   image_data: List[np.ndarray] = None) -> pd.DataFrame:
        """ç”Ÿæˆå¤šæ¨¡æ€äº¤æ˜“ä¿¡å·"""
        print("ğŸ¯ ç”Ÿæˆå¤šæ¨¡æ€äº¤æ˜“ä¿¡å·...")

        # å¤„ç†å„æ¨¡æ€æ•°æ®
        modality_features = {}

        if 'time_series' in self.modalities:
            modality_features['time_series'] = self.process_time_series_data(time_series_data)

        if 'text' in self.modalities and text_data:
            modality_features['text'] = self.process_text_data(text_data)

        if 'image' in self.modalities and image_data:
            modality_features['image'] = self.process_image_data(image_data)

        # èåˆç‰¹å¾
        fused_features = self.fuse_modalities(modality_features)

        # åˆ†æè·¨æ¨¡æ€ç›¸å…³æ€§
        cross_modal_corr = self.analyze_cross_modal_correlations(modality_features)

        # ç”Ÿæˆä¿¡å·
        signals = []

        for i in range(len(time_series_data)):
            # åŸºäºå„æ¨¡æ€çš„ä¿¡å·
            time_series_signal = self._generate_time_series_signal(modality_features.get('time_series', {}), i)
            text_signal = self._generate_text_signal(modality_features.get('text', {}))
            image_signal = self._generate_image_signal(modality_features.get('image', {}))

            # èåˆä¿¡å·
            weights = self._calculate_modality_weights(cross_modal_corr)
            combined_signal = (
                weights.get('time_series', 0.5) * time_series_signal +
                weights.get('text', 0.25) * text_signal +
                weights.get('image', 0.25) * image_signal
            )

            signals.append(np.clip(combined_signal, -1, 1))

        signals_df = pd.DataFrame({
            'signal': signals,
            'time_series_confidence': [abs(time_series_signal)] * len(signals),
            'text_confidence': [abs(text_signal)] * len(signals),
            'image_confidence': [abs(image_signal)] * len(signals),
            'fusion_confidence': [np.mean([abs(time_series_signal), abs(text_signal), abs(image_signal)])] * len(signals)
        }, index=time_series_data.index)

        return signals_df

    def _generate_time_series_signal(self, time_series_features: Dict, index: int) -> float:
        """ç”Ÿæˆæ—¶åºä¿¡å·"""
        signal = 0

        # åŸºäºæŠ€æœ¯æŒ‡æ ‡çš„ä¿¡å·
        if 'rsi' in time_series_features:
            rsi_value = time_series_features['rsi'][0] if time_series_features['rsi'] else 50
            if rsi_value < 30:
                signal += 0.5
            elif rsi_value > 70:
                signal -= 0.5

        # åŸºäºè¶‹åŠ¿çš„ä¿¡å·
        if 'close_trend' in time_series_features:
            trend = time_series_features['close_trend'][0] if time_series_features['close_trend'] else 0
            signal += np.sign(trend) * 0.3

        return np.clip(signal, -1, 1)

    def _generate_text_signal(self, text_features: Dict) -> float:
        """ç”Ÿæˆæ–‡æœ¬ä¿¡å·"""
        signal = 0

        # åŸºäºæƒ…ç»ªçš„ä¿¡å·
        if 'sentiment_score' in text_features:
            sentiment = text_features['sentiment_score'][0] if text_features['sentiment_score'] else 0
            signal += sentiment * 0.8

        # åŸºäºè¯é¢‘çš„ä¿¡å·
        if 'positive_word_count' in text_features and 'negative_word_count' in text_features:
            pos_count = text_features['positive_word_count'][0] if text_features['positive_word_count'] else 0
            neg_count = text_features['negative_word_count'][0] if text_features['negative_word_count'] else 0

            if pos_count + neg_count > 0:
                word_sentiment = (pos_count - neg_count) / (pos_count + neg_count)
                signal += word_sentiment * 0.2

        return np.clip(signal, -1, 1)

    def _generate_image_signal(self, image_features: Dict) -> float:
        """ç”Ÿæˆå›¾åƒä¿¡å·"""
        signal = 0

        # ç®€åŒ–çš„å›¾åƒä¿¡å·ç”Ÿæˆ
        # å®é™…åº”ç”¨ä¸­åº”è¯¥ä½¿ç”¨æ›´å¤æ‚çš„å›¾åƒåˆ†æ
        if image_features:
            # åŸºäºé¢œè‰²ç‰¹å¾çš„ç®€å•ä¿¡å·
            red_features = [v for k, v in image_features.items() if 'mean_r' in k]
            if red_features:
                # çº¢è‰²ç‰¹å¾å¯èƒ½è¡¨ç¤ºè­¦ç¤º
                avg_red = np.mean(red_features)
                if avg_red > 0.6:
                    signal -= 0.3
                elif avg_red < 0.4:
                    signal += 0.3

        return np.clip(signal, -1, 1)

    def _calculate_modality_weights(self, cross_modal_corr: Dict) -> Dict[str, float]:
        """è®¡ç®—æ¨¡æ€æƒé‡"""
        weights = {
            'time_series': 0.6,
            'text': 0.25,
            'image': 0.15
        }

        # åŸºäºç›¸å…³æ€§è°ƒæ•´æƒé‡
        if cross_modal_corr:
            # å¦‚æœç›¸å…³æ€§é«˜ï¼Œé™ä½ä¾èµ–æ€§å¼ºçš„æ¨¡æ€æƒé‡
            high_corr_count = sum(1 for corr in cross_modal_corr.values() if abs(corr) > 0.7)
            if high_corr_count > 0:
                # é‡æ–°åˆ†é…æƒé‡
                weights['time_series'] = 0.7
                weights['text'] = 0.2
                weights['image'] = 0.1

        return weights

    def get_multimodal_insights(self) -> Dict[str, Any]:
        """è·å–å¤šæ¨¡æ€æ´å¯Ÿ"""
        return {
            'modalities': self.modalities,
            'fusion_method': self.fusion_method,
            'cross_modal_correlations': self.cross_modal_correlations,
            'modality_weights': self.fusion_weights,
            'feature_count': len(self.multimodal_features)
        }

    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'modalities': self.modalities,
            'fusion_method': self.fusion_method,
            'is_trained': self.is_trained,
            'torch_available': TORCH_AVAILABLE,
            'model_type': 'Multimodal Market Analyzer'
        }

class TimeSeriesProcessor:
    """æ—¶åºæ•°æ®å¤„ç†å™¨"""
    def extract_features(self, data: pd.DataFrame) -> Dict[str, np.ndarray]:
        """æå–æ—¶åºç‰¹å¾"""
        features = {}
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„æ—¶åºç‰¹å¾æå–
        return features

class TextProcessor:
    """æ–‡æœ¬æ•°æ®å¤„ç†å™¨"""
    def extract_features(self, text: str) -> Dict[str, np.ndarray]:
        """æå–æ–‡æœ¬ç‰¹å¾"""
        features = {}
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„æ–‡æœ¬ç‰¹å¾æå–
        return features

class ImageProcessor:
    """å›¾åƒæ•°æ®å¤„ç†å™¨"""
    def extract_features(self, image: np.ndarray) -> Dict[str, np.ndarray]:
        """æå–å›¾åƒç‰¹å¾"""
        features = {}
        # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„å›¾åƒç‰¹å¾æå–
        return features

# ä¾¿æ·å‡½æ•°
def create_multimodal_analyzer(modalities: List[str] = None, fusion_method: str = 'attention') -> MultimodalMarketAnalyzer:
    """åˆ›å»ºå¤šæ¨¡æ€åˆ†æå™¨å®ä¾‹"""
    return MultimodalMarketAnalyzer(modalities, fusion_method)

def quick_multimodal_analysis(time_series_data: pd.DataFrame, text_data: List[str] = None) -> Dict[str, Any]:
    """å¿«é€Ÿå¤šæ¨¡æ€åˆ†æ"""
    analyzer = MultimodalMarketAnalyzer()

    # ç”Ÿæˆä¿¡å·
    signals = analyzer.generate_multimodal_signals(time_series_data, text_data)

    return {
        'latest_signal': signals['signal'].iloc[-1] if len(signals) > 0 else 0,
        'fusion_confidence': signals['fusion_confidence'].iloc[-1] if len(signals) > 0 else 0,
        'cross_modal_correlations': analyzer.cross_modal_correlations,
        'model_info': analyzer.get_model_info()
    }